{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31686811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "INPUT_DATASET = \"E:/PROJECT/dataset\"\n",
    "\n",
    "BASE_PATH = \"E:/PROJECT/dataset/idc\"\n",
    "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
    "VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
    "TEST_PATH = os.path.sep.join([BASE_PATH, \"testing\"])\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"E:/PROJECT\")\n",
    "from cancernet import config\n",
    "from imutils import paths\n",
    "import random, shutil, os\n",
    "\n",
    "originalPaths=list(paths.list_images(config.INPUT_DATASET))\n",
    "random.seed(7)\n",
    "random.shuffle(originalPaths)\n",
    "\n",
    "index=int(len(originalPaths)*config.TRAIN_SPLIT)\n",
    "trainPaths=originalPaths[:index]\n",
    "testPaths=originalPaths[index:]\n",
    "\n",
    "index=int(len(trainPaths)*config.VAL_SPLIT)\n",
    "valPaths=trainPaths[:index]\n",
    "trainPaths=trainPaths[index:]\n",
    "\n",
    "datasets=[(\"training\", trainPaths, config.TRAIN_PATH),\n",
    "          (\"validation\", valPaths, config.VAL_PATH),\n",
    "          (\"testing\", testPaths, config.TEST_PATH)\n",
    "]\n",
    "\n",
    "for (setType, originalPaths, basePath) in datasets:\n",
    "        print(f'Building {setType} set')\n",
    "\n",
    "        if not os.path.exists(basePath):\n",
    "                print(f'Building directory {basePath}')\n",
    "                os.makedirs(basePath)\n",
    "\n",
    "        for path in originalPaths:\n",
    "                file=path.split(os.path.sep)[-1]\n",
    "                label=file[-5:-4]\n",
    "\n",
    "                labelPath=os.path.sep.join([basePath,label])\n",
    "                if not os.path.exists(labelPath):\n",
    "                        print(f'Building directory {labelPath}')\n",
    "                        os.makedirs(labelPath)\n",
    "\n",
    "                newPath=os.path.sep.join([labelPath, file])\n",
    "                shutil.copy2(path, newPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import SeparableConv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "class CancerNet:\n",
    "  @staticmethod\n",
    "  def build(width,height,depth,classes):\n",
    "    model=Sequential()\n",
    "    shape=(height,width,depth)\n",
    "    channelDim=-1\n",
    "\n",
    "    if K.image_data_format()==\"channels_first\":\n",
    "      shape=(depth,height,width)\n",
    "      channelDim=1\n",
    "\n",
    "    model.add(SeparableConv2D(32, (3,3), padding=\"same\",input_shape=shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=channelDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(SeparableConv2D(64, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=channelDim))\n",
    "    model.add(SeparableConv2D(64, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=channelDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(SeparableConv2D(128, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=channelDim))\n",
    "    model.add(SeparableConv2D(128, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=channelDim))\n",
    "    model.add(SeparableConv2D(128, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=channelDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015aaa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"E:/PROJECT/\")\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import optimizer_v2\n",
    "from keras.optimizer_v2 import adagrad\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from cancernet.cancernet import CancerNet\n",
    "from cancernet import config\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "NUM_EPOCHS=5; INIT_LR=1e-2; BS=32\n",
    "\n",
    "trainPaths=list(paths.list_images(config.TRAIN_PATH))\n",
    "lenTrain=len(trainPaths)\n",
    "lenVal=len(list(paths.list_images(config.VAL_PATH)))\n",
    "lenTest=len(list(paths.list_images(config.TEST_PATH)))\n",
    "\n",
    "trainLabels=[int(p.split(os.path.sep)[-2]) for p in trainPaths]\n",
    "trainLabels=np_utils.to_categorical(trainLabels)\n",
    "classTotals=trainLabels.sum(axis=0)\n",
    "classWeight=dict()\n",
    "for i in range(0,len(classTotals)):\n",
    "    classWeight[i] = classTotals.max()/classTotals[i]\n",
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "  rescale=1/255.0,\n",
    "  rotation_range=20,\n",
    "  zoom_range=0.05,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.05,\n",
    "  horizontal_flip=True,\n",
    "  vertical_flip=True,\n",
    "  fill_mode=\"nearest\")\n",
    "\n",
    "valAug=ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "  config.TRAIN_PATH,\n",
    "  class_mode=\"categorical\",\n",
    "  target_size=(48,48),\n",
    "  color_mode=\"rgb\",\n",
    "  shuffle=True,\n",
    "  batch_size=BS)\n",
    "valGen = valAug.flow_from_directory(\n",
    "  config.VAL_PATH,\n",
    "  class_mode=\"categorical\",\n",
    "  target_size=(48,48),\n",
    "  color_mode=\"rgb\",\n",
    "  shuffle=False,\n",
    "  batch_size=BS)\n",
    "testGen = valAug.flow_from_directory(\n",
    "  config.TEST_PATH,\n",
    "  class_mode=\"categorical\",\n",
    "  target_size=(48,48),\n",
    "  color_mode=\"rgb\",\n",
    "  shuffle=False,\n",
    "  batch_size=BS)\n",
    "\n",
    "model=CancerNet.build(width=48,height=48,depth=3,classes=2)\n",
    "opt=keras.optimizer_v2.adagrad.Adagrad(lr=INIT_LR,decay=INIT_LR/NUM_EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "M=model.fit(\n",
    "  trainGen,\n",
    "  steps_per_epoch=lenTrain//BS,\n",
    "  validation_data=valGen,\n",
    "  validation_steps=lenVal//BS,\n",
    "  class_weight=classWeight,\n",
    "  epochs=NUM_EPOCHS)\n",
    "\n",
    "print(\"Now evaluating the model\")\n",
    "testGen.reset()\n",
    "pred_indices=model.predict_generator(testGen,steps=(lenTest//BS)+1)\n",
    "\n",
    "pred_indices=np.argmax(pred_indices,axis=1)\n",
    "\n",
    "print(classification_report(testGen.classes, pred_indices, target_names=testGen.class_indices.keys()))\n",
    "\n",
    "cm=confusion_matrix(testGen.classes,pred_indices)\n",
    "total=sum(sum(cm))\n",
    "accuracy=(cm[0,0]+cm[1,1])/total\n",
    "specificity=cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print(cm)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), M.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), M.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), M.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), M.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch \")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"Plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70755f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
